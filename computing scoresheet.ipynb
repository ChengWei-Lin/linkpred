{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scientometrics / jasistscientometrics\n",
      "co-author / co-occurrenceco-occurrence\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "journal = input('scientometrics / jasist')\n",
    "entity = input('co-author / co-occurrence')\n",
    "\n",
    "path = os.getcwd()\n",
    "evaluation_path = path+\"\\\\output prediction\\\\{}\\\\{}\\\\evaluation\\\\\".format(journal, entity)\n",
    "result_path = path+\"\\\\output prediction\\\\{}\\\\{}\\\\result\\\\\".format(journal, entity)\n",
    "\n",
    "# betweenness\n",
    "betweenness_path = path+\"\\\\output prediction\\\\{}\\\\{}\\\\edge_betweenness\\\\\".format(journal, entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "netfiles_path = path+\"\\\\data_transformation_output\\\\{}\\\\netfiles\\\\{}\\\\\".format(journal, entity)\n",
    "netfiles_lemma_path = path+\"\\\\data_transformation_output\\\\{}\\\\netfiles\\\\{}\\\\lemma\\\\\".format(journal, entity)\n",
    "netfiles_stem_path = path+\"\\\\data_transformation_output\\\\{}\\\\netfiles\\\\{}\\\\stem\\\\\".format(journal, entity)\n",
    "\n",
    "def get_netfiles(netfiles_path):\n",
    "    netfiles = []\n",
    "    times = []\n",
    "    for f in os.listdir(netfiles_path):\n",
    "        if f.endswith('.net'):\n",
    "            netfiles.append(netfiles_path+f)\n",
    "            times.append(f.split('.')[0])\n",
    "            \n",
    "    return netfiles, times\n",
    "\n",
    "netfiles, times = get_netfiles(netfiles_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\data_transformation_output\\\\scientometrics\\\\netfiles\\\\co-occurrence\\\\2010-2015.net',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\data_transformation_output\\\\scientometrics\\\\netfiles\\\\co-occurrence\\\\2016-2016.net',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\data_transformation_output\\\\scientometrics\\\\netfiles\\\\co-occurrence\\\\2016-2017.net',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\data_transformation_output\\\\scientometrics\\\\netfiles\\\\co-occurrence\\\\2016-2018.net',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\data_transformation_output\\\\scientometrics\\\\netfiles\\\\co-occurrence\\\\2016-2019.net']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_paths = [result_path+times[i+1]+'\\\\' for i in range(len(times)-1)]\n",
    "evaluation_paths = [evaluation_path+times[i+1]+'\\\\' for i in range(len(times)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lemma_paths = [result_path+'lemma\\\\'+times[i+1]+'\\\\' for i in range(len(times)-1)]\n",
    "evaluation_lemma_paths = [evaluation_path+'lemma\\\\'+times[i+1]+'\\\\' for i in range(len(times)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_stem_paths = [result_path+'stem\\\\'+times[i+1]+'\\\\' for i in range(len(times)-1)]\n",
    "evaluation_stem_paths = [evaluation_path+'stem\\\\'+times[i+1]+'\\\\' for i in range(len(times)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\result\\\\stem\\\\2016-2016\\\\',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\result\\\\stem\\\\2016-2017\\\\',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\result\\\\stem\\\\2016-2018\\\\',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\result\\\\stem\\\\2016-2019\\\\']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_stem_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\evaluation\\\\stem\\\\2016-2016\\\\',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\evaluation\\\\stem\\\\2016-2017\\\\',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\evaluation\\\\stem\\\\2016-2018\\\\',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\evaluation\\\\stem\\\\2016-2019\\\\']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_stem_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\result\\\\2016-2016\\\\',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\result\\\\2016-2017\\\\',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\result\\\\2016-2018\\\\',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\result\\\\2016-2019\\\\']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\evaluation\\\\2016-2016\\\\',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\evaluation\\\\2016-2017\\\\',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\evaluation\\\\2016-2018\\\\',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\evaluation\\\\2016-2019\\\\']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2016-2016\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2016\\AdamicAdar.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2016\\CommonNeighbours.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2016\\jaccard.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2016\\katz_beta-0.001.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2016\\katz_beta-0.01.txt\n",
      "\n",
      "2 2016-2017\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2017\\AdamicAdar.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2017\\CommonNeighbours.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2017\\jaccard.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2017\\katz_beta-0.001.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2017\\katz_beta-0.01.txt\n",
      "\n",
      "3 2016-2018\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2018\\AdamicAdar.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2018\\CommonNeighbours.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2018\\jaccard.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2018\\katz_beta-0.001.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2018\\katz_beta-0.01.txt\n",
      "\n",
      "4 2016-2019\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2019\\AdamicAdar.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2019\\CommonNeighbours.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2019\\jaccard.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2019\\katz_beta-0.001.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\2016-2019\\katz_beta-0.01.txt\n",
      "\n",
      "1 2016-2016\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2016\\AdamicAdar.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2016\\CommonNeighbours.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2016\\jaccard.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2016\\katz_beta-0.001.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2016\\katz_beta-0.01.txt\n",
      "\n",
      "2 2016-2017\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2017\\AdamicAdar.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2017\\CommonNeighbours.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2017\\jaccard.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2017\\katz_beta-0.001.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2017\\katz_beta-0.01.txt\n",
      "\n",
      "3 2016-2018\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2018\\AdamicAdar.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2018\\CommonNeighbours.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2018\\jaccard.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2018\\katz_beta-0.001.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2018\\katz_beta-0.01.txt\n",
      "\n",
      "4 2016-2019\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2019\\AdamicAdar.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2019\\CommonNeighbours.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2019\\jaccard.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2019\\katz_beta-0.001.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\result\\stem\\2016-2019\\katz_beta-0.01.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_result(result_paths):\n",
    "    result = dict()\n",
    "    algos = []\n",
    "    for i, time in enumerate(times):\n",
    "        if i<(len(times)-1):\n",
    "            print(i+1, times[i+1])\n",
    "            result[times[i+1]] = dict()\n",
    "            for f in os.listdir(result_paths[i]):\n",
    "                print(result_paths[i]+f)\n",
    "                algo = f.split('.txt')[0]\n",
    "                algos.append(algo)\n",
    "                df_iter = pd.read_csv(result_paths[i-1]+f, header=None, sep='\\t')\n",
    "                df_iter.columns = ['keyword1', 'keyword2', 'weight']\n",
    "                result[times[i+1]][algo] = df_iter\n",
    "            print()\n",
    "    \n",
    "    return result, list(set(algos))\n",
    "\n",
    "result, algos = read_result(result_paths)\n",
    "result_stem, algos = read_result(result_stem_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2016-2016\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2016\\AdamicAdar.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2016\\CommonNeighbours.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2016\\jaccard.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2016\\katz_beta-0.001.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2016\\katz_beta-0.01.txt\n",
      "\n",
      "2 2016-2017\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2017\\AdamicAdar.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2017\\CommonNeighbours.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2017\\jaccard.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2017\\katz_beta-0.001.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2017\\katz_beta-0.01.txt\n",
      "\n",
      "3 2016-2018\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2018\\AdamicAdar.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2018\\CommonNeighbours.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2018\\jaccard.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2018\\katz_beta-0.001.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2018\\katz_beta-0.01.txt\n",
      "\n",
      "4 2016-2019\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2019\\AdamicAdar.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2019\\CommonNeighbours.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2019\\jaccard.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2019\\katz_beta-0.001.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\2016-2019\\katz_beta-0.01.txt\n",
      "\n",
      "1 2016-2016\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2016\\AdamicAdar.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2016\\CommonNeighbours.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2016\\jaccard.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2016\\katz_beta-0.001.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2016\\katz_beta-0.01.txt\n",
      "\n",
      "2 2016-2017\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2017\\AdamicAdar.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2017\\CommonNeighbours.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2017\\jaccard.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2017\\katz_beta-0.001.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2017\\katz_beta-0.01.txt\n",
      "\n",
      "3 2016-2018\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2018\\AdamicAdar.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2018\\CommonNeighbours.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2018\\jaccard.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2018\\katz_beta-0.001.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2018\\katz_beta-0.01.txt\n",
      "\n",
      "4 2016-2019\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2019\\AdamicAdar.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2019\\CommonNeighbours.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2019\\jaccard.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2019\\katz_beta-0.001.txt\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\evaluation\\stem\\2016-2019\\katz_beta-0.01.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_evaluation(evaluation_paths):\n",
    "    evaluation = dict()\n",
    "    for i, time in enumerate(times):\n",
    "        if i<(len(times)-1):\n",
    "            print(i+1, times[i+1])\n",
    "            evaluation[times[i+1]] = dict()\n",
    "            for f in os.listdir(evaluation_paths[i]):\n",
    "                print(evaluation_paths[i]+f)\n",
    "                algo = f.split('.txt')[0]\n",
    "                df_iter = pd.read_csv(evaluation_paths[i-1]+f, header=None, sep=' ')\n",
    "                df_iter.columns = ['tp', 'fp', 'fn', 'tn']\n",
    "                evaluation[times[i+1]][algo] = df_iter\n",
    "            print()\n",
    "    \n",
    "    return evaluation\n",
    "\n",
    "evaluation = read_evaluation(evaluation_paths)\n",
    "evaluation_stem = read_evaluation(evaluation_stem_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read Betweenness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness_paths = [betweenness_path+f for f in os.listdir(betweenness_path) if f.endswith('.txt')]\n",
    "betweenness_stem_paths = [betweenness_path+\"stem\\\\\"+f for f in os.listdir(betweenness_path) if f.endswith('.txt')]\n",
    "betweenness_lemma_paths = [betweenness_path+\"lemma\\\\\"+f for f in os.listdir(betweenness_path) if f.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2016-2016\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\edge_betweenness\\2016-2016.txt\n",
      "\n",
      "2 2016-2017\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\edge_betweenness\\2016-2017.txt\n",
      "\n",
      "3 2016-2018\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\edge_betweenness\\2016-2018.txt\n",
      "\n",
      "4 2016-2019\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\edge_betweenness\\2016-2019.txt\n",
      "\n",
      "1 2016-2016\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\edge_betweenness\\stem\\2016-2016.txt\n",
      "\n",
      "2 2016-2017\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\edge_betweenness\\stem\\2016-2017.txt\n",
      "\n",
      "3 2016-2018\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\edge_betweenness\\stem\\2016-2018.txt\n",
      "\n",
      "4 2016-2019\n",
      "C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\output prediction\\scientometrics\\co-occurrence\\edge_betweenness\\stem\\2016-2019.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_betweenness(betweenness_paths):\n",
    "    betweenness = dict()\n",
    "    for i, f in enumerate(betweenness_paths):\n",
    "        if i<(len(times)-1):\n",
    "            print(i+1, times[i+1])\n",
    "            df_iter = pd.read_csv(f, sep='\\t', header=None)\n",
    "            df_iter.columns = ['keyword1', 'keyword2', 'betweenness']\n",
    "            df_iter = df_iter.set_index(['keyword1', 'keyword2'])\n",
    "            betweenness[times[i+1]] = df_iter.reset_index()\n",
    "            print(f)\n",
    "        print()\n",
    "    return betweenness\n",
    "\n",
    "betweenness = read_betweenness(betweenness_paths)\n",
    "betweenness_stem = read_betweenness(betweenness_stem_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## computing confusion and new evaluation with correct tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import linkpred\n",
    "\n",
    "def compute_df_confusions(i, eva):\n",
    "\n",
    "    def compute_confusion(evaluation, num_linked, num_of_nolink):\n",
    "\n",
    "        def add_0_for_cal(X):\n",
    "\n",
    "            C = pd.DataFrame()\n",
    "            C = C.append([[0, 0, num_linked, num_of_nolink]])\n",
    "            C.columns = X.columns\n",
    "            X = C.append(X)\n",
    "\n",
    "            return X\n",
    "\n",
    "        X = add_0_for_cal(evaluation)[:-1]\n",
    "        Y = add_0_for_cal(evaluation)[1:]\n",
    "        X = X.reset_index()\n",
    "        X = X.drop(columns=['index'])\n",
    "\n",
    "        return Y-X\n",
    "    \n",
    "    # find all possible links in testing period\n",
    "    G = linkpred.read_network(netfiles[i+1]) # t1\n",
    "    n = len(list(G.nodes))\n",
    "    print(\"{} nodes in {}\".format(n, times[i+1]))\n",
    "\n",
    "    all_possible_links = (n*(n-1))/2\n",
    "    print(\"all possible links: {}\".format(all_possible_links))\n",
    "\n",
    "    df_confusions = dict()\n",
    "    # within different algorithms\n",
    "    for k in eva.keys():\n",
    "        print('-'*10, k)\n",
    "\n",
    "        # evaluation = eva[k]\n",
    "        num_linked = int(eva[k]['tp'][0]+eva[k]['fn'][0])\n",
    "\n",
    "        # calculate tn\n",
    "        num_of_nolink = all_possible_links-num_linked\n",
    "        print(\"num of linked:  {}\".format(num_linked))\n",
    "        print(\"num of no link: {}\".format(num_of_nolink))\n",
    "\n",
    "        df_confusion = compute_confusion(eva[k], num_linked, num_of_nolink)\n",
    "        df_confusions[k] = df_confusion\n",
    "\n",
    "        eva[k]['tn'] = np.array([num_of_nolink]*len(eva[k]['fp']))-eva[k]['fp']\n",
    "    \n",
    "    return eva, df_confusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate sensitivity, specificity and YoundenIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_index(eva):\n",
    "    for k in eva.keys():\n",
    "        print('-'*10, k)\n",
    "        x = eva[k]\n",
    "        x['sensitivity'] = x['tp'] / (x['tp'] + x['fn'])\n",
    "        x['specificity'] = x['tn'] / (x['tn'] + x['fp'])\n",
    "\n",
    "        x['YoundenIndex'] = x['sensitivity']+x['specificity']-1\n",
    "\n",
    "        Younden_idxmax = x['YoundenIndex'].idxmax()\n",
    "        print(x.loc[Younden_idxmax], '\\n')\n",
    "    return eva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_predict_result(result, df_confusions):\n",
    "    predict_results = dict()\n",
    "    for k in result.keys():\n",
    "        predict_results[k] = result[k].copy()\n",
    "        predict_results[k]['predict'] = np.array([1]*len(result[k]))\n",
    "        predict_results[k]['actual'] = df_confusions[k]['tp']\n",
    "        \n",
    "    return predict_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all_results(result, predict_results, eva, df_betweenness):\n",
    "    \n",
    "    all_results = dict()\n",
    "\n",
    "    for k in result.keys():\n",
    "        all_results[k] = predict_results[k].join(eva[k])\n",
    "        \n",
    "        # concat with betweenness\n",
    "        left = all_results[k].copy()\n",
    "        right = df_betweenness.copy()\n",
    "        z = pd.merge(left, right, how='outer', on=['keyword1', 'keyword2'])\n",
    "\n",
    "        \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                link            no-link\n",
    "                +--------------+---------------+\n",
    "     predict    | tp           | fp            |\n",
    "     value      | ret & rel    | ret & ~rel    |\n",
    "                +--------------+---------------+\n",
    "     no-predict | fn           | tn            |\n",
    "     NA         | ~ret & rel   | ~ret & ~rel   |\n",
    "                +--------------+---------------+\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        retrieved : a list or set\n",
    "            iterable of the retrieved items\n",
    "\n",
    "        relevant : a list or set\n",
    "            iterable of the relevant items\n",
    "\n",
    "        universe : a list or set, an int or None\n",
    "            If universe is an iterable, it is interpreted as the set of all\n",
    "            items in the system. If universe is an int, it is interpreted as\n",
    "            the *number* of items in the system. This allows for fewer checks\n",
    "            but is more memory-efficient. If universe is None, it is supposed\n",
    "            to be unknown. This still allows for some measures, including\n",
    "            precision and recall, to be calculated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network contains multiple edges. These will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1223 nodes in 2016-2016\n",
      "all possible links: 747253.0\n",
      "---------- AdamicAdar\n",
      "num of linked:  3894\n",
      "num of no link: 743359.0\n",
      "---------- CommonNeighbours\n",
      "num of linked:  3894\n",
      "num of no link: 743359.0\n",
      "---------- jaccard\n",
      "num of linked:  3894\n",
      "num of no link: 743359.0\n",
      "---------- katz_beta-0.001\n",
      "num of linked:  3894\n",
      "num of no link: 743359.0\n",
      "---------- katz_beta-0.01\n",
      "num of linked:  3894\n",
      "num of no link: 743359.0\n",
      "---------- AdamicAdar\n",
      "tp                1657.000000\n",
      "fp               81910.000000\n",
      "fn                2237.000000\n",
      "tn              661449.000000\n",
      "sensitivity          0.425526\n",
      "specificity          0.889811\n",
      "YoundenIndex         0.315337\n",
      "Name: 83566, dtype: float64 \n",
      "\n",
      "---------- CommonNeighbours\n",
      "tp                1638.000000\n",
      "fp               71381.000000\n",
      "fn                2256.000000\n",
      "tn              671978.000000\n",
      "sensitivity          0.420647\n",
      "specificity          0.903975\n",
      "YoundenIndex         0.324622\n",
      "Name: 73018, dtype: float64 \n",
      "\n",
      "---------- jaccard\n",
      "tp                  71.000000\n",
      "fp               11578.000000\n",
      "fn                3823.000000\n",
      "tn              731781.000000\n",
      "sensitivity          0.018233\n",
      "specificity          0.984425\n",
      "YoundenIndex         0.002658\n",
      "Name: 11648, dtype: float64 \n",
      "\n",
      "---------- katz_beta-0.001\n",
      "tp                1679.000000\n",
      "fp               74165.000000\n",
      "fn                2215.000000\n",
      "tn              669194.000000\n",
      "sensitivity          0.431176\n",
      "specificity          0.900230\n",
      "YoundenIndex         0.331406\n",
      "Name: 75843, dtype: float64 \n",
      "\n",
      "---------- katz_beta-0.01\n",
      "tp                1703.000000\n",
      "fp               78692.000000\n",
      "fn                2191.000000\n",
      "tn              664667.000000\n",
      "sensitivity          0.437339\n",
      "specificity          0.894140\n",
      "YoundenIndex         0.331479\n",
      "Name: 80394, dtype: float64 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network contains multiple edges. These will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2349 nodes in 2016-2017\n",
      "all possible links: 2757726.0\n",
      "---------- AdamicAdar\n",
      "num of linked:  1164\n",
      "num of no link: 2756562.0\n",
      "---------- CommonNeighbours\n",
      "num of linked:  1164\n",
      "num of no link: 2756562.0\n",
      "---------- jaccard\n",
      "num of linked:  1164\n",
      "num of no link: 2756562.0\n",
      "---------- katz_beta-0.001\n",
      "num of linked:  1164\n",
      "num of no link: 2756562.0\n",
      "---------- katz_beta-0.01\n",
      "num of linked:  1164\n",
      "num of no link: 2756562.0\n",
      "---------- AdamicAdar\n",
      "tp              6.510000e+02\n",
      "fp              3.001720e+05\n",
      "fn              5.130000e+02\n",
      "tn              2.456390e+06\n",
      "sensitivity     5.592784e-01\n",
      "specificity     8.911064e-01\n",
      "YoundenIndex    4.503847e-01\n",
      "Name: 300822, dtype: float64 \n",
      "\n",
      "---------- CommonNeighbours\n",
      "tp              6.370000e+02\n",
      "fp              3.396260e+05\n",
      "fn              5.270000e+02\n",
      "tn              2.416936e+06\n",
      "sensitivity     5.472509e-01\n",
      "specificity     8.767936e-01\n",
      "YoundenIndex    4.240445e-01\n",
      "Name: 340262, dtype: float64 \n",
      "\n",
      "---------- jaccard\n",
      "tp              7.150000e+02\n",
      "fp              5.284130e+05\n",
      "fn              4.490000e+02\n",
      "tn              2.228149e+06\n",
      "sensitivity     6.142612e-01\n",
      "specificity     8.083072e-01\n",
      "YoundenIndex    4.225684e-01\n",
      "Name: 529127, dtype: float64 \n",
      "\n",
      "---------- katz_beta-0.001\n",
      "tp              6.680000e+02\n",
      "fp              2.113450e+05\n",
      "fn              4.960000e+02\n",
      "tn              2.545217e+06\n",
      "sensitivity     5.738832e-01\n",
      "specificity     9.233302e-01\n",
      "YoundenIndex    4.972134e-01\n",
      "Name: 212012, dtype: float64 \n",
      "\n",
      "---------- katz_beta-0.01\n",
      "tp              6.880000e+02\n",
      "fp              2.597820e+05\n",
      "fn              4.760000e+02\n",
      "tn              2.496780e+06\n",
      "sensitivity     5.910653e-01\n",
      "specificity     9.057587e-01\n",
      "YoundenIndex    4.968240e-01\n",
      "Name: 260469, dtype: float64 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network contains multiple edges. These will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3364 nodes in 2016-2018\n",
      "all possible links: 5656566.0\n",
      "---------- AdamicAdar\n",
      "num of linked:  2168\n",
      "num of no link: 5654398.0\n",
      "---------- CommonNeighbours\n",
      "num of linked:  2168\n",
      "num of no link: 5654398.0\n",
      "---------- jaccard\n",
      "num of linked:  2168\n",
      "num of no link: 5654398.0\n",
      "---------- katz_beta-0.001\n",
      "num of linked:  2168\n",
      "num of no link: 5654398.0\n",
      "---------- katz_beta-0.01\n",
      "num of linked:  2168\n",
      "num of no link: 5654398.0\n",
      "---------- AdamicAdar\n",
      "tp              1.276000e+03\n",
      "fp              4.686490e+05\n",
      "fn              8.920000e+02\n",
      "tn              5.185749e+06\n",
      "sensitivity     5.885609e-01\n",
      "specificity     9.171178e-01\n",
      "YoundenIndex    5.056787e-01\n",
      "Name: 469924, dtype: float64 \n",
      "\n",
      "---------- CommonNeighbours\n",
      "tp              1.297000e+03\n",
      "fp              5.256490e+05\n",
      "fn              8.710000e+02\n",
      "tn              5.128749e+06\n",
      "sensitivity     5.982472e-01\n",
      "specificity     9.070371e-01\n",
      "YoundenIndex    5.052844e-01\n",
      "Name: 526945, dtype: float64 \n",
      "\n",
      "---------- jaccard\n",
      "tp              1.297000e+03\n",
      "fp              5.278310e+05\n",
      "fn              8.710000e+02\n",
      "tn              5.126567e+06\n",
      "sensitivity     5.982472e-01\n",
      "specificity     9.066512e-01\n",
      "YoundenIndex    5.048985e-01\n",
      "Name: 529127, dtype: float64 \n",
      "\n",
      "---------- katz_beta-0.001\n",
      "tp              1.539000e+03\n",
      "fp              7.787750e+05\n",
      "fn              6.290000e+02\n",
      "tn              4.875623e+06\n",
      "sensitivity     7.098708e-01\n",
      "specificity     8.622709e-01\n",
      "YoundenIndex    5.721418e-01\n",
      "Name: 780313, dtype: float64 \n",
      "\n",
      "---------- katz_beta-0.01\n",
      "tp              1.537000e+03\n",
      "fp              7.691740e+05\n",
      "fn              6.310000e+02\n",
      "tn              4.885224e+06\n",
      "sensitivity     7.089483e-01\n",
      "specificity     8.639689e-01\n",
      "YoundenIndex    5.729172e-01\n",
      "Name: 770710, dtype: float64 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network contains multiple edges. These will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4172 nodes in 2016-2019\n",
      "all possible links: 8700706.0\n",
      "---------- AdamicAdar\n",
      "num of linked:  3082\n",
      "num of no link: 8697624.0\n",
      "---------- CommonNeighbours\n",
      "num of linked:  3082\n",
      "num of no link: 8697624.0\n",
      "---------- jaccard\n",
      "num of linked:  3082\n",
      "num of no link: 8697624.0\n",
      "---------- katz_beta-0.001\n",
      "num of linked:  3082\n",
      "num of no link: 8697624.0\n",
      "---------- katz_beta-0.01\n",
      "num of linked:  3082\n",
      "num of no link: 8697624.0\n",
      "---------- AdamicAdar\n",
      "tp              1.852000e+03\n",
      "fp              5.254160e+05\n",
      "fn              1.230000e+03\n",
      "tn              8.172208e+06\n",
      "sensitivity     6.009085e-01\n",
      "specificity     9.395909e-01\n",
      "YoundenIndex    5.404994e-01\n",
      "Name: 527267, dtype: float64 \n",
      "\n",
      "---------- CommonNeighbours\n",
      "tp              1.852000e+03\n",
      "fp              5.269670e+05\n",
      "fn              1.230000e+03\n",
      "tn              8.170657e+06\n",
      "sensitivity     6.009085e-01\n",
      "specificity     9.394125e-01\n",
      "YoundenIndex    5.403210e-01\n",
      "Name: 528818, dtype: float64 \n",
      "\n",
      "---------- jaccard\n",
      "tp              1.852000e+03\n",
      "fp              5.272760e+05\n",
      "fn              1.230000e+03\n",
      "tn              8.170348e+06\n",
      "sensitivity     6.009085e-01\n",
      "specificity     9.393770e-01\n",
      "YoundenIndex    5.402855e-01\n",
      "Name: 529127, dtype: float64 \n",
      "\n",
      "---------- katz_beta-0.001\n",
      "tp              2.298000e+03\n",
      "fp              9.799840e+05\n",
      "fn              7.840000e+02\n",
      "tn              7.717640e+06\n",
      "sensitivity     7.456197e-01\n",
      "specificity     8.873274e-01\n",
      "YoundenIndex    6.329471e-01\n",
      "Name: 982281, dtype: float64 \n",
      "\n",
      "---------- katz_beta-0.01\n",
      "tp              2.314000e+03\n",
      "fp              1.024569e+06\n",
      "fn              7.680000e+02\n",
      "tn              7.673055e+06\n",
      "sensitivity     7.508112e-01\n",
      "specificity     8.822013e-01\n",
      "YoundenIndex    6.330124e-01\n",
      "Name: 1026882, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_confusions = dict()\n",
    "all_results = dict()\n",
    "for i, time in enumerate(times):\n",
    "    if i < len(times)-1:\n",
    "        \n",
    "        res = result[times[i+1]]\n",
    "        eva = evaluation[times[i+1]]\n",
    "        \n",
    "        eva, df_confusions[times[i+1]] = compute_df_confusions(i, eva)\n",
    "        eva = calculate_index(eva)\n",
    "        predict_results = calculate_predict_result(res, df_confusions[times[i+1]])\n",
    "        all_results[times[i+1]] = calculate_all_results(res, predict_results, eva, betweenness[times[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, time in enumerate(times):\n",
    "    if i < len(times)-1:\n",
    "        all_results[times[i+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword1</th>\n",
       "      <th>keyword2</th>\n",
       "      <th>weight</th>\n",
       "      <th>predict</th>\n",
       "      <th>actual</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>YoundenIndex</th>\n",
       "      <th>betweenness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Bibliometrics</td>\n",
       "      <td>0.218742</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3893.0</td>\n",
       "      <td>743359.0</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Research evaluation</td>\n",
       "      <td>Bibliometrics</td>\n",
       "      <td>0.187846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3892.0</td>\n",
       "      <td>743359.0</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Citation analysis</td>\n",
       "      <td>Bibliometrics</td>\n",
       "      <td>0.133139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3891.0</td>\n",
       "      <td>743359.0</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h-index</td>\n",
       "      <td>Bibliometrics</td>\n",
       "      <td>0.129363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3890.0</td>\n",
       "      <td>743359.0</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Citation</td>\n",
       "      <td>Bibliometrics</td>\n",
       "      <td>0.125690</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3890.0</td>\n",
       "      <td>743358.0</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7875543</th>\n",
       "      <td>usnwr</td>\n",
       "      <td>worldclass univers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7875544</th>\n",
       "      <td>vo viewer</td>\n",
       "      <td>web of scienc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7875545</th>\n",
       "      <td>water secur</td>\n",
       "      <td>web of scienc wo databas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7875546</th>\n",
       "      <td>web</td>\n",
       "      <td>webometr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7875547</th>\n",
       "      <td>world univers rank</td>\n",
       "      <td>young univers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7875548 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    keyword1                  keyword2    weight  predict  \\\n",
       "0                      Italy             Bibliometrics  0.218742      1.0   \n",
       "1        Research evaluation             Bibliometrics  0.187846      1.0   \n",
       "2          Citation analysis             Bibliometrics  0.133139      1.0   \n",
       "3                    h-index             Bibliometrics  0.129363      1.0   \n",
       "4                   Citation             Bibliometrics  0.125690      1.0   \n",
       "...                      ...                       ...       ...      ...   \n",
       "7875543                usnwr        worldclass univers       NaN      NaN   \n",
       "7875544            vo viewer             web of scienc       NaN      NaN   \n",
       "7875545          water secur  web of scienc wo databas       NaN      NaN   \n",
       "7875546                  web                  webometr       NaN      NaN   \n",
       "7875547   world univers rank             young univers       NaN      NaN   \n",
       "\n",
       "         actual   tp   fp      fn        tn  sensitivity  specificity  \\\n",
       "0           1.0  1.0  0.0  3893.0  743359.0     0.000257     1.000000   \n",
       "1           1.0  2.0  0.0  3892.0  743359.0     0.000514     1.000000   \n",
       "2           1.0  3.0  0.0  3891.0  743359.0     0.000770     1.000000   \n",
       "3           1.0  4.0  0.0  3890.0  743359.0     0.001027     1.000000   \n",
       "4           0.0  4.0  1.0  3890.0  743358.0     0.001027     0.999999   \n",
       "...         ...  ...  ...     ...       ...          ...          ...   \n",
       "7875543     NaN  NaN  NaN     NaN       NaN          NaN          NaN   \n",
       "7875544     NaN  NaN  NaN     NaN       NaN          NaN          NaN   \n",
       "7875545     NaN  NaN  NaN     NaN       NaN          NaN          NaN   \n",
       "7875546     NaN  NaN  NaN     NaN       NaN          NaN          NaN   \n",
       "7875547     NaN  NaN  NaN     NaN       NaN          NaN          NaN   \n",
       "\n",
       "         YoundenIndex  betweenness  \n",
       "0            0.000257          NaN  \n",
       "1            0.000514          NaN  \n",
       "2            0.000770          NaN  \n",
       "3            0.001027          NaN  \n",
       "4            0.001026          NaN  \n",
       "...               ...          ...  \n",
       "7875543           NaN     0.000001  \n",
       "7875544           NaN     0.000381  \n",
       "7875545           NaN     0.000001  \n",
       "7875546           NaN     0.000077  \n",
       "7875547           NaN     0.000001  \n",
       "\n",
       "[7875548 rows x 13 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results[times[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-743360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529129</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529130</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529131</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529132</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529133</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>529134 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tp   fp   fn        tn\n",
       "0       1.0  0.0 -1.0 -743360.0\n",
       "1       1.0  0.0 -1.0       0.0\n",
       "2       1.0  0.0 -1.0       0.0\n",
       "3       1.0  0.0 -1.0       0.0\n",
       "4       0.0  1.0  0.0       0.0\n",
       "...     ...  ...  ...       ...\n",
       "529129  0.0  1.0  0.0       0.0\n",
       "529130  0.0  1.0  0.0       0.0\n",
       "529131  0.0  1.0  0.0       0.0\n",
       "529132  0.0  1.0  0.0       0.0\n",
       "529133  0.0  1.0  0.0       0.0\n",
       "\n",
       "[529134 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusions[times[1]]['']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## see if edges already appeared in training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat 4 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AdamicAdar</th>\n",
       "      <th>CommonNeighbours</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>katz_beta-0.001</th>\n",
       "      <th>katz_beta-0.01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword1</th>\n",
       "      <th>keyword2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(h)over-bar</th>\n",
       "      <th>'Journal impact factor</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.127996e-08</td>\n",
       "      <td>3.981630e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">(h)over-bar-core</th>\n",
       "      <th>'Journal impact factor</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.127996e-08</td>\n",
       "      <td>3.981630e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(h)over-bar</th>\n",
       "      <td>2.345938</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.007060e-03</td>\n",
       "      <td>1.077617e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2-Mode network</th>\n",
       "      <th>'Journal impact factor</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.108731e-09</td>\n",
       "      <td>2.693100e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(h)over-bar</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.045400e-09</td>\n",
       "      <td>1.670000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">z-score</th>\n",
       "      <th>research assessment</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.017000e-12</td>\n",
       "      <td>1.170000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solar cells (DSSCs)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.900000e-14</td>\n",
       "      <td>1.900000e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v-Index</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.189000e-12</td>\n",
       "      <td>5.890000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w-Index</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.221000e-12</td>\n",
       "      <td>7.210000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z-Index</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.684000e-12</td>\n",
       "      <td>1.584000e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7871787 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         AdamicAdar  CommonNeighbours  \\\n",
       "keyword1         keyword2                                               \n",
       "(h)over-bar      'Journal impact factor         NaN               NaN   \n",
       "(h)over-bar-core 'Journal impact factor         NaN               NaN   \n",
       "                 (h)over-bar               2.345938               7.0   \n",
       "2-Mode network   'Journal impact factor         NaN               NaN   \n",
       "                 (h)over-bar                    NaN               NaN   \n",
       "...                                             ...               ...   \n",
       "z-score          research assessment            NaN               NaN   \n",
       "                 solar cells (DSSCs)            NaN               NaN   \n",
       "                 v-Index                        NaN               NaN   \n",
       "                 w-Index                        NaN               NaN   \n",
       "                 z-Index                        NaN               NaN   \n",
       "\n",
       "                                          jaccard  katz_beta-0.001  \\\n",
       "keyword1         keyword2                                            \n",
       "(h)over-bar      'Journal impact factor       NaN     2.127996e-08   \n",
       "(h)over-bar-core 'Journal impact factor       NaN     2.127996e-08   \n",
       "                 (h)over-bar             0.777778     1.007060e-03   \n",
       "2-Mode network   'Journal impact factor       NaN     1.108731e-09   \n",
       "                 (h)over-bar                  NaN     1.045400e-09   \n",
       "...                                           ...              ...   \n",
       "z-score          research assessment          NaN     1.017000e-12   \n",
       "                 solar cells (DSSCs)          NaN     1.900000e-14   \n",
       "                 v-Index                      NaN     4.189000e-12   \n",
       "                 w-Index                      NaN     5.221000e-12   \n",
       "                 z-Index                      NaN     9.684000e-12   \n",
       "\n",
       "                                         katz_beta-0.01  \n",
       "keyword1         keyword2                                \n",
       "(h)over-bar      'Journal impact factor    3.981630e-05  \n",
       "(h)over-bar-core 'Journal impact factor    3.981630e-05  \n",
       "                 (h)over-bar               1.077617e-02  \n",
       "2-Mode network   'Journal impact factor    2.693100e-06  \n",
       "                 (h)over-bar               1.670000e-06  \n",
       "...                                                 ...  \n",
       "z-score          research assessment       1.170000e-08  \n",
       "                 solar cells (DSSCs)       1.900000e-09  \n",
       "                 v-Index                   5.890000e-08  \n",
       "                 w-Index                   7.210000e-08  \n",
       "                 z-Index                   1.584000e-07  \n",
       "\n",
       "[7871787 rows x 5 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2016-2016\n",
      "AdamicAdar\n",
      "CommonNeighbours\n",
      "jaccard\n",
      "katz_beta-0.001\n",
      "katz_beta-0.01\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set a frame with no defined index and a value that cannot be converted to a Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_ensure_valid_index\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   3053\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3054\u001b[1;33m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3055\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mis_empty_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m                 \u001b[1;31m# gh-17261\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36mis_empty_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[0mis_list_like_without_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[0mis_simple_empty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_list_like_without_dtype\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mis_none\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_simple_empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1478\u001b[0m         raise ValueError(\n\u001b[1;32m-> 1479\u001b[1;33m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1480\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-f963065a9b40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mdf_all_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2937\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2938\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2997\u001b[0m         \"\"\"\n\u001b[0;32m   2998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2999\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3000\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3001\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_ensure_valid_index\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   3055\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3056\u001b[0m                 raise ValueError(\n\u001b[1;32m-> 3057\u001b[1;33m                     \u001b[1;34m\"Cannot set a frame with no defined index \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3058\u001b[0m                     \u001b[1;34m\"and a value that cannot be converted to a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3059\u001b[0m                     \u001b[1;34m\"Series\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set a frame with no defined index and a value that cannot be converted to a Series"
     ]
    }
   ],
   "source": [
    "df_all_results = dict()\n",
    "\n",
    "for i, time in enumerate(times):\n",
    "    if i < (len(times)-1):\n",
    "        print(i+1, times[i+1])\n",
    "        df = pd.DataFrame()\n",
    "        for algo in sorted(algos):\n",
    "            print(algo)\n",
    "            df_iter = result[times[i+1]][algo].set_index(['keyword1', 'keyword2'])\n",
    "            df = pd.concat([df, df_iter], axis=1, sort=False)\n",
    "            \n",
    "        df.columns = sorted(algos)\n",
    "        df_all_results[times[i+1]] = df\n",
    "        print()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
