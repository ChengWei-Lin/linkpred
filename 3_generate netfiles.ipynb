{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate .net file\n",
    "\n",
    "    *network Informetrics1990-2004\n",
    "    *vertices 632\n",
    "    632 \"Shailendra, K\"\n",
    "    *edges\n",
    "    1 402 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scientometrics / jasistscientometrics\n",
      "co-author / co-occurrenceco-occurrence\n"
     ]
    }
   ],
   "source": [
    "journal = input('scientometrics / jasist')\n",
    "entity = input('co-author / co-occurrence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = os.getcwd()\n",
    "data_path = path+'\\\\data_transformation_output\\\\{}\\\\{}\\\\'.format(journal, entity)\n",
    "data_lemma_path = path+'\\\\data_transformation_output\\\\{}\\\\{}\\\\lemma\\\\'.format(journal, entity)\n",
    "data_stem_path = path+'\\\\data_transformation_output\\\\{}\\\\{}\\\\stem\\\\'.format(journal, entity)\n",
    "\n",
    "def read_dir(data_path):\n",
    "    times = [f for f in os.listdir(data_path) if f.startswith('20')]\n",
    "    data_path = [data_path+f for f in os.listdir(data_path) if f.startswith('20')]\n",
    "    all_files = [data_path[i]+\"\\\\\"+f for i in range(len(times)) for f in os.listdir(data_path[i])]\n",
    "    node_files = all_files[1::2]\n",
    "    edge_files = all_files[0::2]\n",
    "    \n",
    "    return times, node_files, edge_files\n",
    "\n",
    "times, node_files, edge_files = read_dir(data_stem_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2010-2015', '2016-2016', '2016-2017', '2016-2018', '2016-2019']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\USER\\\\Desktop\\\\linchengwei_linkpred\\\\data_transformation_output\\\\scientometrics\\\\co-occurrence\\\\stem\\\\2010-2015\\\\edge.csv',\n",
       " 'C:\\\\Users\\\\USER\\\\Desktop\\\\linchengwei_linkpred\\\\data_transformation_output\\\\scientometrics\\\\co-occurrence\\\\stem\\\\2016-2016\\\\edge.csv',\n",
       " 'C:\\\\Users\\\\USER\\\\Desktop\\\\linchengwei_linkpred\\\\data_transformation_output\\\\scientometrics\\\\co-occurrence\\\\stem\\\\2016-2017\\\\edge.csv',\n",
       " 'C:\\\\Users\\\\USER\\\\Desktop\\\\linchengwei_linkpred\\\\data_transformation_output\\\\scientometrics\\\\co-occurrence\\\\stem\\\\2016-2018\\\\edge.csv',\n",
       " 'C:\\\\Users\\\\USER\\\\Desktop\\\\linchengwei_linkpred\\\\data_transformation_output\\\\scientometrics\\\\co-occurrence\\\\stem\\\\2016-2019\\\\edge.csv']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes, df_edges = dict(), dict()\n",
    "for i, time in enumerate(times):\n",
    "    df = pd.read_csv(node_files[i], index_col=0)\n",
    "    df_nodes[time] = df\n",
    "    \n",
    "for i, time in enumerate(times):\n",
    "    df = pd.read_csv(edge_files[i], index_col=0)\n",
    "    df_edges[time] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\USER\\\\Desktop\\\\linchengwei_linkpred\\\\data_transformation_output\\\\scientometrics\\\\netfiles\\\\co-occurrence\\\\'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = path+\"\\\\data_transformation_output\\\\{}\\\\netfiles\\\\{}\\\\\".format(journal, entity)\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\USER\\\\Desktop\\\\linchengwei_linkpred\\\\data_transformation_output\\\\scientometrics\\\\netfiles\\\\co-occurrence\\\\lemma\\\\'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lemma_path = path+\"\\\\data_transformation_output\\\\{}\\\\netfiles\\\\{}\\\\lemma\\\\\".format(journal, entity)\n",
    "output_lemma_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\USER\\\\Desktop\\\\linchengwei_linkpred\\\\data_transformation_output\\\\scientometrics\\\\netfiles\\\\co-occurrence\\\\stem\\\\'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_stem_path = path+\"\\\\data_transformation_output\\\\{}\\\\netfiles\\\\{}\\\\stem\\\\\".format(journal, entity)\n",
    "output_stem_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_netfiles(df_node, df_edge, time, output_path):\n",
    "    netfile_path = output_path+\"{}.net\".format(time)\n",
    "    \n",
    "    f = open(netfile_path, 'w', encoding='utf-8')\n",
    "    f.write(\"*{}.net\\n\".format(time))\n",
    "    f.write(\"*vertices {}\\n\".format(len(df_node)))\n",
    "    for i in range(len(df_node)):\n",
    "        ID = int(df_node.iloc[i]['id'])\n",
    "        label = str(df_node.iloc[i]['label'])\n",
    "        f.write('{} \"{}\"\\n'.format(ID, label))\n",
    "    f.write('*edges\\n')\n",
    "    for i in range(len(df_edge)):\n",
    "        source = int(df_edge.iloc[i][0])\n",
    "        target = int(df_edge.iloc[i][1])\n",
    "        weight = int(df_edge.iloc[i][2])\n",
    "        f.write(\"{} {} {}\\n\".format(source, target, weight))\n",
    "    f.close()\n",
    "    print('-'*10, netfile_path, '-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- C:\\Users\\USER\\Desktop\\linchengwei_linkpred\\data_transformation_output\\scientometrics\\netfiles\\co-occurrence\\stem\\2010-2015.net ----------\n",
      "---------- C:\\Users\\USER\\Desktop\\linchengwei_linkpred\\data_transformation_output\\scientometrics\\netfiles\\co-occurrence\\stem\\2016-2016.net ----------\n",
      "---------- C:\\Users\\USER\\Desktop\\linchengwei_linkpred\\data_transformation_output\\scientometrics\\netfiles\\co-occurrence\\stem\\2016-2017.net ----------\n",
      "---------- C:\\Users\\USER\\Desktop\\linchengwei_linkpred\\data_transformation_output\\scientometrics\\netfiles\\co-occurrence\\stem\\2016-2018.net ----------\n",
      "---------- C:\\Users\\USER\\Desktop\\linchengwei_linkpred\\data_transformation_output\\scientometrics\\netfiles\\co-occurrence\\stem\\2016-2019.net ----------\n"
     ]
    }
   ],
   "source": [
    "for i, time in enumerate(times):\n",
    "    generate_netfiles(df_nodes[time], df_edges[time], time, output_stem_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
