{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use following algorithms\n",
    "1. [jaccard](https://networkx.github.io/documentation/networkx-1.9/reference/generated/networkx.algorithms.link_prediction.jaccard_coefficient.html)\n",
    "2. [adamic adar](https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.link_prediction.adamic_adar_index.html)\n",
    "3. [preferential attachment](https://networkx.github.io/documentation/stable/reference/algorithms/generated/networkx.algorithms.link_prediction.preferential_attachment.html#networkx.algorithms.link_prediction.preferential_attachment)\n",
    "4. [katz](https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.centrality.katz_centrality.html) (and try different beta, maybe max_power) \n",
    "\n",
    "    4.1 small beta value (float), will find it more similar to CommonNeighbor algo, which doesn't consider other nodes other than neighbors  \n",
    "    4.2 max_power (int), which means to what extent of path length will be considered\n",
    "\n",
    "We want this for output\n",
    "* P is whether Katz value exceed the threshold\n",
    "\n",
    "                Katz,   P,    TP,    normalized betweenness of the whole graph\n",
    "        A, B    0.05,   1,    1,     \n",
    "        C, D    0.07,   1,    0,     \n",
    "        E, F    0.10,   0,    0,     \n",
    "        \n",
    "# How we find the best threshold\n",
    "To find the best sensitivity and specificity, we use \n",
    "[YoudenIndex](https://en.wikipedia.org/wiki/Youden%27s_J_statistic?fbclid=IwAR3OICm3oJQQnopIKeflrpd1K-DcxahLE9IerxPfb8k6uISWt30D4DexuCA)    \n",
    "\n",
    "    J = sensitivity + specificity - 1\n",
    "    sensitivity = tp / tp + fn (ALL YES)\n",
    "    specificity = tn / fp + tn (ALL NO )\n",
    "    \n",
    "## sensitivity and specificity\n",
    "[wikipedia](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scientometrics / jasistscientometrics\n",
      "co-author / co-occurrenceco-occurrence\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import linkpred\n",
    "import networkx as nx\n",
    "import linkpred\n",
    "\n",
    "journal = input('scientometrics / jasist')\n",
    "entity = input('co-author / co-occurrence')\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "netfiles_path = path+\"\\\\data_transformation_output\\\\{}\\\\netfiles\\\\{}\\\\\".format(journal, entity)\n",
    "netfiles_lemma_path = path+\"\\\\data_transformation_output\\\\{}\\\\netfiles\\\\{}\\\\lemma\\\\\".format(journal, entity)\n",
    "netfiles_stem_path = path+\"\\\\data_transformation_output\\\\{}\\\\netfiles\\\\{}\\\\stem\\\\\".format(journal, entity)\n",
    "\n",
    "def get_netfiles(netfiles_path):\n",
    "    netfiles = []\n",
    "    times = []\n",
    "    for f in os.listdir(netfiles_path):\n",
    "        if f.endswith('.net'):\n",
    "            netfiles.append(netfiles_path+f)\n",
    "            times.append(f.split('.')[0])\n",
    "            \n",
    "    return netfiles, times\n",
    "\n",
    "netfiles, times = get_netfiles(netfiles_stem_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin / stem / lemma ?stem\n"
     ]
    }
   ],
   "source": [
    "user_input = input('origin / stem / lemma ?')\n",
    "\n",
    "if user_input=='stem':\n",
    "    result_output_path = path+'\\\\output prediction\\\\{}\\\\{}\\\\result\\\\stem\\\\'.format(journal, entity)\n",
    "    evaluation_output_path = path+'\\\\output prediction\\\\{}\\\\{}\\\\evaluation\\\\stem\\\\'.format(journal, entity)\n",
    "    betweenness_output_path = path+'\\\\output prediction\\\\{}\\\\{}\\\\edge_betweenness\\\\stem\\\\'.format(journal, entity)\n",
    "    \n",
    "elif user_input=='lemma':\n",
    "    result_output_path = path+'\\\\output prediction\\\\{}\\\\{}\\\\result\\\\lemma\\\\'.format(journal, entity)\n",
    "    evaluation_output_path = path+'\\\\output prediction\\\\{}\\\\{}\\\\evaluation\\\\lemma\\\\'.format(journal, entity)\n",
    "    betweenness_output_path = path+'\\\\output prediction\\\\{}\\\\{}\\\\edge_betweenness\\\\lemma\\\\'.format(journal, entity)\n",
    "else:\n",
    "    result_output_path = path+'\\\\output prediction\\\\{}\\\\{}\\\\result\\\\'.format(journal, entity)\n",
    "    evaluation_output_path = path+'\\\\output prediction\\\\{}\\\\{}\\\\evaluation\\\\'.format(journal, entity)\n",
    "    betweenness_output_path = path+'\\\\output prediction\\\\{}\\\\{}\\\\edge_betweenness\\\\'.format(journal, entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\edge_betweenness\\\\stem\\\\'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betweenness_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Existed!!\n",
      "File Existed!!\n",
      "File Existed!!\n",
      "File Existed!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\evaluation\\\\stem\\\\2016-2016',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\evaluation\\\\stem\\\\2016-2017',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\evaluation\\\\stem\\\\2016-2018',\n",
       " 'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\evaluation\\\\stem\\\\2016-2019']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_output_dir(output_path):\n",
    "    for i in range(len(times)-1):\n",
    "        try:\n",
    "            os.mkdir(output_path+times[i+1])\n",
    "        except FileExistsError:\n",
    "            print(\"File Existed!!\")\n",
    "            \n",
    "    output_path = [output_path+t for t in os.listdir(output_path) if t.startswith('20')]\n",
    "    return output_path\n",
    "generate_output_dir(result_output_path)\n",
    "generate_output_dir(evaluation_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\edge_betweenness\\\\stem\\\\'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betweenness_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Liser\\\\Desktop\\\\linchengwei_link_prediction\\\\sync\\\\output prediction\\\\scientometrics\\\\co-occurrence\\\\result\\\\stem\\\\'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_edge_betweenness(edge_betweenness_result, t, betweenness_output_path):\n",
    "    f = open(betweenness_output_path+'{}.txt'.format(t), 'w', encoding='utf-8')\n",
    "    for kw, score in edge_betweenness_result.items():\n",
    "        f.write(\"{}\\t{}\\t{}\\n\".format(kw[0], kw[1], score))\n",
    "    f.close()\n",
    "    print('Save edge betweenness!')\n",
    "    \n",
    "    \n",
    "def remove_nodes_not_in_training(training, test):\n",
    "    x = test.copy()\n",
    "    print(\"nodes: {}\\nedges: {}\".format(x.number_of_nodes(), x.number_of_edges()))\n",
    "    intersect_nodes = set(list(test.nodes)).intersection(set(list(training.nodes)))\n",
    "    testing_nodes_not_in_training = set(list(test.nodes))-intersect_nodes\n",
    "\n",
    "    x.remove_nodes_from(testing_nodes_not_in_training)\n",
    "    print(\"nodes: {}\\nedges: {}\".format(x.number_of_nodes(), x.number_of_edges()))\n",
    "    \n",
    "    return x\n",
    "\n",
    "def predict_jaccard(G, test, t):\n",
    "    jaccard = linkpred.predictors.Jaccard(G) # , excluded=G.edges()\n",
    "    jaccard_results = jaccard.predict()\n",
    "\n",
    "    jaccard_test_set = set(linkpred.evaluation.Pair(u, v) for u, v in test.edges())\n",
    "    jaccard_evaluation = linkpred.evaluation.EvaluationSheet(jaccard_results, jaccard_test_set)\n",
    "\n",
    "    jaccard_results.to_file(result_output_path+'{}\\\\jaccard.txt'.format(t), delimiter='\\t', encoding='utf-8')\n",
    "\n",
    "    jaccard_evaluation.to_file(evaluation_output_path+'{}\\\\jaccard.txt'.format(t))\n",
    "    print('Saved Jaccard!')\n",
    "    \n",
    "def predict_AdamicAdar(G, test, t):\n",
    "    AdamicAdar = linkpred.predictors.AdamicAdar(G)\n",
    "    AdamicAdar_results = AdamicAdar.predict()\n",
    "\n",
    "    AdamicAdar_test_set = set(linkpred.evaluation.Pair(u, v) for u, v in test.edges())\n",
    "    AdamicAdar_evaluation = linkpred.evaluation.EvaluationSheet(AdamicAdar_results, AdamicAdar_test_set)\n",
    "\n",
    "    AdamicAdar_results.to_file(result_output_path+'{}\\\\AdamicAdar.txt'.format(t), delimiter='\\t', encoding='utf-8')\n",
    "\n",
    "    AdamicAdar_evaluation.to_file(evaluation_output_path+'{}\\\\AdamicAdar.txt'.format(t))\n",
    "    print('Saved AdamicAdar!')\n",
    "        \n",
    "def predict_AdamicAdar(G, test, t):\n",
    "    AdamicAdar = linkpred.predictors.AdamicAdar(G)\n",
    "    AdamicAdar_results = AdamicAdar.predict()\n",
    "\n",
    "    AdamicAdar_test_set = set(linkpred.evaluation.Pair(u, v) for u, v in test.edges())\n",
    "    AdamicAdar_evaluation = linkpred.evaluation.EvaluationSheet(AdamicAdar_results, AdamicAdar_test_set)\n",
    "\n",
    "    AdamicAdar_results.to_file(result_output_path+'\\{}\\\\AdamicAdar.txt'.format(t), delimiter='\\t', encoding='utf-8')\n",
    "\n",
    "    AdamicAdar_evaluation.to_file(evaluation_output_path+'{}\\\\AdamicAdar.txt'.format(t))\n",
    "    print('Saved AdamicAdar!')\n",
    "    \n",
    "def predict_katz(G, test, t, beta=0.001, max_power=5):\n",
    "    katz = linkpred.predictors.Katz(G)\n",
    "    katz_results = katz.predict(beta=beta, max_power=max_power)\n",
    "\n",
    "    katz_test_set = set(linkpred.evaluation.Pair(u, v) for u, v in test.edges())\n",
    "    katz_evaluation = linkpred.evaluation.EvaluationSheet(katz_results, katz_test_set)\n",
    "\n",
    "    katz_results.to_file(result_output_path+'{}\\\\katz_{}.txt'.format(t, \"beta-{}\".format(str(beta))), delimiter='\\t', encoding='utf-8')\n",
    "\n",
    "    katz_evaluation.to_file(evaluation_output_path+'{}\\\\katz_{}.txt'.format(t, \"beta-{}\".format(str(beta))))\n",
    "    print('Saved katz!'+\" beta-{}\".format(str(beta)))\n",
    "\n",
    "def predict_CommonNeighbours(G, test, t):\n",
    "    CommonNeighbours = linkpred.predictors.CommonNeighbours(G)\n",
    "    CommonNeighbours_results = CommonNeighbours.predict()\n",
    "\n",
    "    CommonNeighbours_test_set = set(linkpred.evaluation.Pair(u, v) for u, v in test.edges())\n",
    "    CommonNeighbours_evaluation = linkpred.evaluation.EvaluationSheet(CommonNeighbours_results, CommonNeighbours_test_set)\n",
    "\n",
    "    CommonNeighbours_results.to_file(result_output_path+'{}\\\\CommonNeighbours.txt'.format(t), delimiter='\\t', encoding='utf-8')\n",
    "\n",
    "    CommonNeighbours_evaluation.to_file(evaluation_output_path+'{}\\\\CommonNeighbours.txt'.format(t))\n",
    "    print('Saved CommonNeighbours!')\n",
    "\n",
    "def predict_PreferentialAttatchment(G, test, t):\n",
    "    PreferentialAttatchment = nx.preferential_attachment(G)\n",
    "    \n",
    "    \n",
    "    PreferentialAttatchment_test_set = set(linkpred.evaluation.Pair(u, v) for u, v in test.edges())\n",
    "    PreferentialAttatchment_evaluation = linkpred.evaluation.EvaluationSheet(PreferentialAttatchment, PreferentialAttatchment_test_set)\n",
    "    \n",
    "    \n",
    "def main(testing_file, t, training_file=netfiles[0]):\n",
    "    training_file = training_file\n",
    "    testing_file = testing_file\n",
    "    # read train\n",
    "    G = linkpred.read_network(training_file)\n",
    "    \n",
    "    # sometimes work perfectly but sometimes raise AsserionError because of self-loop\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    \n",
    "    # read test\n",
    "    test = linkpred.read_network(testing_file)\n",
    "    test.remove_edges_from(nx.selfloop_edges(test))\n",
    "    \n",
    "    # Computing Edge Betweenness in full testing network\n",
    "    edge_betweenness_result = nx.algorithms.centrality.edge_betweenness_centrality(test)\n",
    "    print(\"edge_betweenness_result: {}\".format(len(edge_betweenness_result)))\n",
    "    save_edge_betweenness(edge_betweenness_result, t, betweenness_output_path)\n",
    "    \n",
    "    training = G.copy()\n",
    "    \n",
    "    # remove nodes not in training\n",
    "    test = remove_nodes_not_in_training(training, test)\n",
    "    print('Removed nodes not in training')\n",
    "    \n",
    "    # 1\n",
    "    print('-'*10, 'jaccard')\n",
    "    predict_jaccard(G, test, t)\n",
    "        \n",
    "    # 2\n",
    "    print('-'*10, 'AdamicAdar')\n",
    "    predict_AdamicAdar(G, test, t)\n",
    "    \n",
    "    # 3\n",
    "    print('-'*10, 'katz')\n",
    "    predict_katz(G, test, t, beta=0.001, max_power=5)\n",
    "    \n",
    "    # 4\n",
    "    print('-'*10, 'katz')\n",
    "    predict_katz(G, test, t, beta=0.01, max_power=5)\n",
    "    \n",
    "    # 5\n",
    "    print('-'*10, 'CommonNeighbours')\n",
    "    predict_CommonNeighbours(G, test, t)\n",
    "    \n",
    "    # 6\n",
    "    # print('-'*10, 'preferential_attachment')\n",
    "    # predict_preferential_attachment(G, test, times)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-2016 C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\data_transformation_output\\scientometrics\\netfiles\\co-occurrence\\stem\\2016-2016.net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network contains multiple edges. These will be ignored.\n",
      "Network contains multiple edges. These will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_betweenness_result: 3761\n",
      "Save edge betweenness!\n",
      "nodes: 1178\n",
      "edges: 3761\n",
      "nodes: 479\n",
      "edges: 1310\n",
      "Removed nodes not in training\n",
      "---------- jaccard\n",
      "Saved Jaccard!\n",
      "---------- AdamicAdar\n",
      "Saved AdamicAdar!\n",
      "---------- katz\n",
      "Computing matrix powers: [############################################################] 5/5\n",
      "Saved katz! beta-0.001\n",
      "---------- katz\n",
      "Computing matrix powers: [############################################################] 5/5\n",
      "Saved katz! beta-0.01\n",
      "---------- CommonNeighbours\n",
      "Saved CommonNeighbours!\n",
      "2016-2017 C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\data_transformation_output\\scientometrics\\netfiles\\co-occurrence\\stem\\2016-2017.net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network contains multiple edges. These will be ignored.\n",
      "Network contains multiple edges. These will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_betweenness_result: 7785\n",
      "Save edge betweenness!\n",
      "nodes: 2221\n",
      "edges: 7785\n",
      "nodes: 748\n",
      "edges: 2505\n",
      "Removed nodes not in training\n",
      "---------- jaccard\n",
      "Saved Jaccard!\n",
      "---------- AdamicAdar\n",
      "Saved AdamicAdar!\n",
      "---------- katz\n",
      "Computing matrix powers: [############################################################] 5/5\n",
      "Saved katz! beta-0.001\n",
      "---------- katz\n",
      "Computing matrix powers: [############################################################] 5/5\n",
      "Saved katz! beta-0.01\n",
      "---------- CommonNeighbours\n",
      "Saved CommonNeighbours!\n",
      "2016-2018 C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\data_transformation_output\\scientometrics\\netfiles\\co-occurrence\\stem\\2016-2018.net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network contains multiple edges. These will be ignored.\n",
      "Network contains multiple edges. These will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_betweenness_result: 11929\n",
      "Save edge betweenness!\n",
      "nodes: 3148\n",
      "edges: 11929\n",
      "nodes: 913\n",
      "edges: 3527\n",
      "Removed nodes not in training\n",
      "---------- jaccard\n",
      "Saved Jaccard!\n",
      "---------- AdamicAdar\n",
      "Saved AdamicAdar!\n",
      "---------- katz\n",
      "Computing matrix powers: [############################################################] 5/5\n",
      "Saved katz! beta-0.001\n",
      "---------- katz\n",
      "Computing matrix powers: [############################################################] 5/5\n",
      "Saved katz! beta-0.01\n",
      "---------- CommonNeighbours\n",
      "Saved CommonNeighbours!\n",
      "2016-2019 C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\data_transformation_output\\scientometrics\\netfiles\\co-occurrence\\stem\\2016-2019.net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network contains multiple edges. These will be ignored.\n",
      "Network contains multiple edges. These will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_betweenness_result: 15510\n",
      "Save edge betweenness!\n",
      "nodes: 3884\n",
      "edges: 15510\n",
      "nodes: 1027\n",
      "edges: 4413\n",
      "Removed nodes not in training\n",
      "---------- jaccard\n",
      "Saved Jaccard!\n",
      "---------- AdamicAdar\n",
      "Saved AdamicAdar!\n",
      "---------- katz\n",
      "Computing matrix powers: [############################################################] 5/5\n",
      "Saved katz! beta-0.001\n",
      "---------- katz\n",
      "Computing matrix powers: [############################################################] 5/5\n",
      "Saved katz! beta-0.01\n",
      "---------- CommonNeighbours\n",
      "Saved CommonNeighbours!\n"
     ]
    }
   ],
   "source": [
    "for i, time in enumerate(times):\n",
    "    if i < (len(times)-1):\n",
    "        testing_file = netfiles[i+1]\n",
    "        print(times[i+1], testing_file)\n",
    "        main(testing_file, t=times[i+1], training_file=netfiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-2016 C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\data_transformation_output\\scientometrics\\netfiles\\co-occurrence\\stem\\2016-2016.net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network contains multiple edges. These will be ignored.\n",
      "Network contains multiple edges. These will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: 1178\n",
      "edges: 3761\n",
      "nodes: 479\n",
      "edges: 1310\n",
      "Removed nodes not in training\n",
      "---------- jaccard\n",
      "---------- AdamicAdar\n",
      "---------- katz\n",
      "---------- katz\n",
      "---------- CommonNeighbours\n",
      "Saved CommonNeighbours!\n",
      "2016-2017 C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\data_transformation_output\\scientometrics\\netfiles\\co-occurrence\\stem\\2016-2017.net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network contains multiple edges. These will be ignored.\n",
      "Network contains multiple edges. These will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: 2221\n",
      "edges: 7785\n",
      "nodes: 748\n",
      "edges: 2505\n",
      "Removed nodes not in training\n",
      "---------- jaccard\n",
      "---------- AdamicAdar\n",
      "---------- katz\n",
      "---------- katz\n",
      "---------- CommonNeighbours\n",
      "Saved CommonNeighbours!\n",
      "2016-2018 C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\data_transformation_output\\scientometrics\\netfiles\\co-occurrence\\stem\\2016-2018.net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network contains multiple edges. These will be ignored.\n",
      "Network contains multiple edges. These will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: 3148\n",
      "edges: 11929\n",
      "nodes: 913\n",
      "edges: 3527\n",
      "Removed nodes not in training\n",
      "---------- jaccard\n",
      "---------- AdamicAdar\n",
      "---------- katz\n",
      "---------- katz\n",
      "---------- CommonNeighbours\n",
      "Saved CommonNeighbours!\n",
      "2016-2019 C:\\Users\\Liser\\Desktop\\linchengwei_link_prediction\\sync\\data_transformation_output\\scientometrics\\netfiles\\co-occurrence\\stem\\2016-2019.net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network contains multiple edges. These will be ignored.\n",
      "Network contains multiple edges. These will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: 3884\n",
      "edges: 15510\n",
      "nodes: 1027\n",
      "edges: 4413\n",
      "Removed nodes not in training\n",
      "---------- jaccard\n",
      "---------- AdamicAdar\n",
      "---------- katz\n",
      "---------- katz\n",
      "---------- CommonNeighbours\n",
      "Saved CommonNeighbours!\n"
     ]
    }
   ],
   "source": [
    "for i, time in enumerate(times):\n",
    "    if i < (len(times)-1):\n",
    "        testing_file = netfiles[i+1]\n",
    "        print(times[i+1], testing_file)\n",
    "        main(testing_file, t=times[i+1], training_file=netfiles[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try preferential attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard = linkpred.predictors.Jaccard(G)\n",
    "jaccard_results = jaccard.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Competency', 'Internet and web learning', 24)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "PreferentialAttatchment = nx.preferential_attachment(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full example\n",
    "https://github.com/rafguns/linkpred/issues/12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tn value is -1, something's wrong\n",
    "    Solved, with the correct number of tp, fp, fn, can calculate the number of tn\n",
    "    tp + fn = num_of_link in testing network\n",
    "    tp + fp = num_of_predict_link\n",
    "    tn = all_possible_link - tp - fp - fn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
